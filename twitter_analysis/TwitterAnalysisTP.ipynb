{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f1704c",
   "metadata": {},
   "source": [
    "![TP](../TeachersPro-logo-color.png)\n",
    "\n",
    "# Twitter - Topic Modeling\n",
    "\n",
    "### Lenin Escobar <lenin.escobar@net.teacherspro.com> - Descriptive analytics (18-January-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b811843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%load_ext memory_profiler\n",
    "%matplotlib inline\n",
    "%run TwitterAnalysisHelper.ipynb\n",
    "%run TwitterAnalysisGeneralHelper.ipynb\n",
    "%run TwitterAnalysis_Plot.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1499bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a02e3",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:powderblue;\">Loading Raw Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70578ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plottingHelper = PlottingHelper(version = \"1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e58b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to sqlite3 database\n",
    "#I know I'm using the same data source used for training. However, this data source is really dynamic so,\n",
    "#we present new rows every time run the backend process to collect new tweets.\n",
    "#It's also known that we need to train our model from time to time\n",
    "#(this period is not currently defined so far)\n",
    "dbConn = Sqlite3Db('data/social_network.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869828f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbConn.query('''SELECT insert_timestamp, tweet_timestamp, tweet_term, tweet, place_type, place_name, place_full_name, place_country_code, place_country FROM Tweets; ''')\n",
    "\n",
    "sqlStmRes = dbConn.cursor.fetchall()\n",
    "#print(type(sqlStmRes))\n",
    "#print(sqlStmRes)\n",
    "df_Tweets_original = pd.DataFrame(sqlStmRes, columns =['insert_timestamp','tweet_timestamp','tweet_term', 'tweet', 'place_type', 'place_name', 'place_full_name', 'place_country_code', 'place_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing sqlite3 datbase connection\n",
    "dbConn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e67ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_original.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3 style=\"background-color:powderblue;\">Cleaning Raw Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaningHelper = CleaningHelper(version = \"1.0\")\n",
    "print(cleaningHelper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There should be no null\n",
    "cleaningHelper.get_nulls_data(df_Tweets_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The original data is untouchable\n",
    "df_Tweets_mod = df_Tweets_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97eca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to check the tweet terms, tweet dates and places at first\n",
    "df_Tweets_mod['tweet_timestamp_date'] = df_Tweets_mod['tweet_timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d18543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod['tweet_str'] = df_Tweets_mod['tweet'].str.decode(\"utf-8\")\n",
    "df_Tweets_mod['tweet_term_str'] = df_Tweets_mod['tweet_term'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ab28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3 style=\"background-color:powderblue;\">Raw Data Plotting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "plottingHelper = PlottingHelper(version = \"1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a31ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plottingHelper._df_cat = df_Tweets_mod\n",
    "ipywidgets.interact(plottingHelper.func_count_cat_plotty, \\\n",
    "                x_var_size=ipywidgets.IntSlider(layout={'border': '1px solid black'}, min=1, max=100, value=10, step=1, description=\"Num.Records\"), \\\n",
    "                x_var = ipywidgets.Dropdown(layout={'border': '1px solid black'}, options=[\"tweet_term_str\",\"tweet_str\",\"place_type\",\"place_name\", \\\n",
    "                                                                                           \"place_full_name\",\"place_country_code\",\"place_country\",\"tweet_timestamp_date\"], description=\"Feature\"), \\\n",
    "                x_var_asc = ipywidgets.Checkbox(layout={'border': '1px solid black'}, value=False, description=\"Asc. Order\"), \\\n",
    "                ax_title = ipywidgets.Textarea(layout={'border': '1px solid black'}, value=\"Tweets by Feature\", description=\"Title\") \\\n",
    "               );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3440be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3 style=\"background-color:powderblue;\">Cleaning Pre-processed data with Spacy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166095ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets of punctuation in variable result \n",
    "punctuation_str = string.punctuation  \n",
    "punctuation_str #I want to know if @ is actually include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop words Set\n",
    "#stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stop_words = cleaningHelper.get_custom_stop_words(spacy_ = spacy_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#English parser object\n",
    "parser = spacy.lang.en.English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a74471",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaningTweets = CleaningTweets(version = \"1.0\", spacy_ = spacy_lg, parser_ = parser, punctuation_str_ = punctuation_str, stop_words_ = stop_words)\n",
    "print(cleaningTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_tokens = cleaningTweets.get_words_df(df_Tweets_ = df_Tweets_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_tokens.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c291ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_tokens.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f517732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_tokens.groupby(['token_']).token_.value_counts().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 tokens\n",
    "df_doc_tokens_grp = df_doc_tokens[['token_']].groupby(['token_'])['token_'] \\\n",
    "                             .count() \\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['count'], ascending=False) \\\n",
    "                             .head(10)\n",
    "df_doc_tokens_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_doc_tokens = cleaningTweets.get_words_list(df_Tweets_ = df_doc_tokens)\n",
    "#ls_doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = collections.Counter(ls_doc_tokens)\n",
    "word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate mask\n",
    "char_mask = np.array(Image.open(\"covid19.png\")) \n",
    "#Instantiate the wordcloud object\n",
    "wc = wordcloud.WordCloud(background_color='white', max_words=300, stopwords=stop_words, collocations=False, max_font_size=40, random_state=42, mask=char_mask)\n",
    "# Generate word cloud\n",
    "wc=wc.generate(\" \".join(ls_doc_tokens).lower())\n",
    "# Show word cloud\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3 style=\"background-color:powderblue;\">Preparing the corpus</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf25b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_Tweets_mod[\"processed_tweet_str\"] = df_Tweets_mod[\"tweet_str\"].apply(cleaningTweets.get_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13318dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod[\"processed_tweet_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"tweet_str\"]\n",
    "df_clean = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ff04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.append({'tweet_str': 'thank share quote ðŸŒº ðŸŒ¸'}, ignore_index=True)\n",
    "df_clean = df_clean.append({'tweet_str': '@testuser'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d862c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"processed_tweet_str\"] = df_clean[\"tweet_str\"].apply(cleaningTweets.get_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f06d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer\n",
    "#countVectorizer = CountVectorizer(min_df=0.02)\n",
    "countVectorizer = CountVectorizer()\n",
    "countVectorizerData = countVectorizer.fit_transform(df_Tweets_mod[\"processed_tweet_str\"])\n",
    "print(type(countVectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countVectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countVectorizerData.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    #min_df=0.1, \n",
    "    #max_df=1.0, \n",
    "    stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "#data_vectorized = vectorizer.fit_transform(corpus)\n",
    "data_vectorized = vectorizer.fit_transform(df_Tweets_mod[\"processed_tweet_str\"])\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72417f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c21317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_vectorized.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized_csc = data_vectorized.tocsc(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5aa1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized_csc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 10\n",
    "NUM_PASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d456c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#Working with gensim#\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod[\"processed_tweet_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod['processed_tweet_str_tokens'] = df_Tweets_mod[\"processed_tweet_str\"].apply(cleaningTweets.get_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09710cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweets_mod['processed_tweet_str_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(df_Tweets_mod['processed_tweet_str_tokens'])\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a corpus object \n",
    "corpus = [id2word.doc2bow(d) for d in df_Tweets_mod['processed_tweet_str_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f98bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3 style=\"background-color:powderblue;\">Loading our pre-trained model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fd25ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eae3411a3008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPkl_Filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mPickled_TM_Model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mPickled_TM_Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "Pkl_Filename = \"models/Topic_mode_.pkl\"\n",
    "\n",
    "with open(Pkl_Filename, 'rb') as file:\n",
    "    Pickled_TM_Model = pickle.load(file)\n",
    "\n",
    "Pickled_TM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d5b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp3.9.9",
   "language": "python",
   "name": "nlp3.9.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
